{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a440b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tech\n",
      "[nltk_data]     Line\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Tech Line\\AppData\\Local\\Temp\\ipykernel_5808\\137614874.py:15: DtypeWarning: Columns (20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  news_dataset = pd.read_csv(r\"C:\\Users\\Tech Line\\Desktop\\1111\\fake-new-detection-machine-learning\\data set\\test.csv\")\n",
      "C:\\Users\\Tech Line\\AppData\\Local\\Temp\\ipykernel_5808\\137614874.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  news_dataset['content'] = news_dataset['author'].fillna('') + ' ' + news_dataset['title'].fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "title           0\n",
      "author          0\n",
      "text            0\n",
      "label           0\n",
      "               ..\n",
      "Unnamed: 743    0\n",
      "Unnamed: 744    0\n",
      "Unnamed: 745    0\n",
      "Unnamed: 746    0\n",
      "content         0\n",
      "Length: 748, dtype: int64\n",
      "Accuracy score on the training data: 0.9755527210884354\n",
      "Accuracy score on the test data: 0.5017006802721088\n",
      "[0.]\n",
      "The news is Real\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import Random Forest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset and combine 'author' and 'title'\n",
    "news_dataset = pd.read_csv(r\"C:\\Users\\Tech Line\\Desktop\\1111\\fake-new-detection-machine-learning\\data set\\test.csv\")\n",
    "\n",
    "# replacing the null values with an empty string\n",
    "news_dataset = news_dataset.fillna('')\n",
    "\n",
    "news_dataset['content'] = news_dataset['author'].fillna('') + ' ' + news_dataset['title'].fillna('') \n",
    "\n",
    "# counting the number of missing values in the dataset\n",
    "news_dataset.isnull().sum()\n",
    "\n",
    "print(news_dataset.isnull().sum())\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X = news_dataset.drop(columns='label')\n",
    "Y = news_dataset['label']\n",
    "\n",
    "# Text preprocessing using stemming\n",
    "port_stem = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stemming(content):\n",
    "    content = re.sub('[^a-zA-Z]', ' ', content.lower())\n",
    "    words = [port_stem.stem(word) for word in content.split() if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "news_dataset['content'] = news_dataset['content'].apply(stemming)\n",
    "\n",
    "\n",
    "# Ensure 'label' column is numeric\n",
    "news_dataset['label'] = pd.to_numeric(news_dataset['label'], errors='coerce')\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X = news_dataset.drop(columns='label')\n",
    "Y = news_dataset['label']\n",
    "\n",
    "# Separating the data and label\n",
    "X = news_dataset['content'].values\n",
    "Y = news_dataset['label'].values\n",
    "\n",
    "# Converting the textual data to numerical data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "Y = np.nan_to_num(Y, nan=0)  # Replace missing values with a default value, e.g., 0\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "\n",
    "# Training a Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "training_data_accuracy = accuracy_score(model.predict(X_train), Y_train)\n",
    "test_data_accuracy = accuracy_score(model.predict(X_test), Y_test)\n",
    "\n",
    "print('Accuracy score on the training data:', training_data_accuracy)\n",
    "print('Accuracy score on the test data:', test_data_accuracy)\n",
    "\n",
    "X_new = X_test[5]\n",
    "\n",
    "prediction = model.predict(X_new.reshape(1, -1))\n",
    "print(prediction)\n",
    "\n",
    "if prediction[0] == 0:\n",
    "    print('The news is Real')\n",
    "else:\n",
    "    print('The news is Fake')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4a8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
